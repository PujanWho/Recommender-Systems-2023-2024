{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52343546",
   "metadata": {},
   "source": [
    "Recommender System 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806eacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d756b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Surprise Reader\n",
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58474dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MovieLens dataset using Surprise library\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcaed356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88333488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x13558292190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use SVD for collaborative filtering\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cfe00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top N recommendations for a user\n",
    "def get_top_recommendations(user_id, num_recommendations=10):\n",
    "    # Build anti-test set for the given user\n",
    "    anti_testset = trainset.build_anti_testset()\n",
    "    anti_testset = [elem for elem in anti_testset if elem[0] == user_id]\n",
    "\n",
    "    # Predict ratings for unrated items\n",
    "    predictions = model.test(anti_testset)\n",
    "\n",
    "    # Organize predictions by movie ID\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Sort predictions by estimated rating\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:num_recommendations]\n",
    "\n",
    "    # Display the top N movie recommendations\n",
    "    print(f'\\nTop {num_recommendations} Recommended Movies for User {user_id}:')\n",
    "    for i, (movie_id, estimated_rating) in enumerate(top_n[user_id], start=1):\n",
    "        print(f\"{i}. MovieID: {movie_id}, Estimated Rating: {estimated_rating}\")\n",
    "\n",
    "# Example usage\n",
    "#get_top_recommendations(user_id=\"15\")\n",
    "#get_top_recommendations(user_id=\"21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fb33116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter userId (or type 'exit' to end): 15\n",
      "\n",
      "Top 10 Recommended Movies for User 15:\n",
      "1. MovieID: 64, Estimated Rating: 4.442799511860893\n",
      "2. MovieID: 318, Estimated Rating: 4.342392217854538\n",
      "3. MovieID: 22, Estimated Rating: 4.204762073752003\n",
      "4. MovieID: 427, Estimated Rating: 4.1339288808736026\n",
      "5. MovieID: 172, Estimated Rating: 4.1032433141901485\n",
      "6. MovieID: 313, Estimated Rating: 4.093795306573339\n",
      "7. MovieID: 199, Estimated Rating: 4.066429653129308\n",
      "8. MovieID: 151, Estimated Rating: 4.039588349976615\n",
      "9. MovieID: 357, Estimated Rating: 3.9743703780525594\n",
      "10. MovieID: 12, Estimated Rating: 3.9426108644419773\n",
      "Enter userId (or type 'exit' to end): exit\n"
     ]
    }
   ],
   "source": [
    "# Simple Command-Line Interface for User Interaction\n",
    "while True:\n",
    "    try:\n",
    "        # Get user input for userId and movieId\n",
    "        user_id = str(input(\"Enter userId (or type 'exit' to end): \"))\n",
    "        if user_id.lower() == 'exit':\n",
    "            break\n",
    "\n",
    "        # Get the top N recommendations for the user\n",
    "        get_top_recommendations(user_id)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b586e2",
   "metadata": {},
   "source": [
    "Recommender System 1 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc9f8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9357\n",
      "\n",
      "RMSE on the test set: 0.935693575561328\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "predictions = model.test(testset)# Calculate RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'\\nRMSE on the test set: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d419dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG at 10: 1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary to store top-N recommendations for each user\n",
    "top_n = defaultdict(list)\n",
    "for uid, iid, true_r, est, _ in predictions:\n",
    "    top_n[uid].append((iid, est))\n",
    "\n",
    "# Function to calculate Discounted Cumulative Gain (DCG) at k\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum((2 ** r - 1) / np.log2(np.arange(2, r.size + 2)))\n",
    "\n",
    "# Function to calculate Normalized Discounted Cumulative Gain (NDCG) at k\n",
    "def ndcg_at_k(predictions, k):\n",
    "    ndcg_sum = 0\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        # Extract true ratings for the user\n",
    "        true_ratings = [true_r for (_, true_r) in user_ratings]\n",
    "\n",
    "        # Extract predicted ratings for the recommended items\n",
    "        predicted_ratings = [est for (_, est) in user_ratings]\n",
    "\n",
    "        # Calculate NDCG for the user\n",
    "        ndcg = dcg_at_k(predicted_ratings, k) / dcg_at_k(true_ratings, k)\n",
    "\n",
    "        # Accumulate NDCG for all users\n",
    "        ndcg_sum += ndcg\n",
    "\n",
    "    # Average NDCG across all users\n",
    "    average_ndcg = ndcg_sum / len(top_n)\n",
    "    return average_ndcg\n",
    "\n",
    "# Calculate NDCG at k (adjust k as needed)\n",
    "k_ndcg = 10\n",
    "average_ndcg = ndcg_at_k(predictions, k_ndcg)\n",
    "print(f'Average NDCG at {k_ndcg}: {average_ndcg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4df35b",
   "metadata": {},
   "source": [
    "Recommender System 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7219736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ModzL\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ModzL\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ModzL\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ModzL\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\ModzL\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2615\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.8958\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8630\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.8391\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13566236dc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# RS2: Collaborative Filtering with Neural Network\n",
    "# Convert Surprise trainset to DataFrame for movie names\n",
    "ratings_df = pd.DataFrame(trainset.all_ratings(), columns=['user', 'item', 'rating'])\n",
    "\n",
    "# Build a neural network model for collaborative filtering\n",
    "num_users = trainset.n_users + 1\n",
    "num_items = trainset.n_items + 1\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=(1,))\n",
    "item_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=num_users, output_dim=50)(user_input)\n",
    "item_embedding = tf.keras.layers.Embedding(input_dim=num_items, output_dim=50)(item_input)\n",
    "\n",
    "# Concatenate user and item embeddings\n",
    "concatenated = tf.keras.layers.Concatenate()([user_embedding, item_embedding])\n",
    "flatten = tf.keras.layers.Flatten()(concatenated)\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='linear')(dense_layer)  # Changed output activation function\n",
    "\n",
    "model_rs2 = tf.keras.models.Model(inputs=[user_input, item_input], outputs=output_layer)\n",
    "\n",
    "model_rs2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the neural network model\n",
    "model_rs2.fit([ratings_df['user'], ratings_df['item']], ratings_df['rating'], epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b2a88bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID is?:15\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "\n",
      "Top 10 Recommended Movies for User 15:\n",
      "1182. MovieID: 1182.0, Predicted Rating: 4.904898643493652\n",
      "119. MovieID: 119.0, Predicted Rating: 4.728442192077637\n",
      "763. MovieID: 763.0, Predicted Rating: 4.693665504455566\n",
      "486. MovieID: 486.0, Predicted Rating: 4.616649150848389\n",
      "604. MovieID: 604.0, Predicted Rating: 4.613925933837891\n",
      "1072. MovieID: 1072.0, Predicted Rating: 4.606298923492432\n",
      "991. MovieID: 991.0, Predicted Rating: 4.6060991287231445\n",
      "357. MovieID: 357.0, Predicted Rating: 4.605318069458008\n",
      "63. MovieID: 63.0, Predicted Rating: 4.58200216293335\n",
      "1176. MovieID: 1176.0, Predicted Rating: 4.581923961639404\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to get movie recommendations for a user using the deep learning model (RS2)\n",
    "def get_movie_recommendations(user_id, model, trainset, num_recommendations=10):\n",
    "    # Get all item IDs\n",
    "    all_item_ids = np.array(list(range(1, trainset.n_items + 1)))\n",
    "\n",
    "    # Repeat the user ID for all items\n",
    "    user_ids = np.full_like(all_item_ids, user_id)\n",
    "\n",
    "    # Predict ratings for the user and all items\n",
    "    ratings = model.predict([user_ids, all_item_ids])\n",
    "\n",
    "    # Create DataFrame with item IDs and predicted ratings\n",
    "    predictions_df = pd.DataFrame({'item': all_item_ids, 'predicted_rating': ratings.flatten()})\n",
    "\n",
    "    # Exclude items the user has already rated\n",
    "    user_ratings = trainset.ur[user_id]\n",
    "    rated_item_ids = [iid for (iid, _) in user_ratings]\n",
    "    predictions_df = predictions_df[~predictions_df['item'].isin(rated_item_ids)]\n",
    "\n",
    "    # Sort items by predicted rating in descending order\n",
    "    top_recommendations = predictions_df.sort_values(by='predicted_rating', ascending=False).head(num_recommendations)\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "\n",
    "user_id_to_recommend = int(input(\"userID is?:\"))\n",
    "num_recs = 10\n",
    "recommendations = get_movie_recommendations(user_id_to_recommend, model_rs2, trainset)\n",
    "\n",
    "# Display the top N movie recommendations\n",
    "print(f'\\nTop {num_recs} Recommended Movies for User {user_id_to_recommend}:')\n",
    "for i, row in recommendations.iterrows():\n",
    "    print(f\"{i + 1}. MovieID: {row['item']}, Predicted Rating: {row['predicted_rating']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e21ec7",
   "metadata": {},
   "source": [
    "Recommender System 2 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "724fab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "RMSE for RS2 (Neural Collaborative Filtering): 1.3237130534847015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Convert user_ids and item_ids to integers\n",
    "user_ids_rs2 = np.array([int(uid) for uid, _, _ in testset])\n",
    "item_ids_rs2 = np.array([int(iid) for _, iid, _ in testset])\n",
    "\n",
    "# Ensure that user_ids and item_ids are within the expected range\n",
    "user_ids_rs2 = np.clip(user_ids_rs2, 0, num_users - 1)\n",
    "item_ids_rs2 = np.clip(item_ids_rs2, 0, num_items - 1)\n",
    "\n",
    "# Use model_rs2.predict for each pair of user_id and item_id\n",
    "predictions_rs2 = model_rs2.predict([user_ids_rs2, item_ids_rs2])\n",
    "estimated_ratings = [pred[0] for pred in predictions_rs2]\n",
    "\n",
    "rmse_rs2 = np.sqrt(mean_squared_error(estimated_ratings, [rating for _, _, rating in testset]))\n",
    "print(f\"RMSE for RS2 (Neural Collaborative Filtering): {rmse_rs2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2059edb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "NDCG for RS2 (Neural Collaborative Filtering): 0.9688771666404502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Get the true ratings for the test set\n",
    "true_ratings_rs2 = np.array([rating for _, _, rating in testset])\n",
    "\n",
    "# Use model_rs2.predict for each pair of user_id and item_id\n",
    "predictions_rs2 = model_rs2.predict([user_ids_rs2, item_ids_rs2])\n",
    "estimated_ratings = np.array([pred[0] for pred in predictions_rs2])\n",
    "\n",
    "# Ensure that estimated ratings are within the valid range (e.g., between 1 and 5)\n",
    "estimated_ratings = np.clip(estimated_ratings, 1, 5)\n",
    "\n",
    "# Calculate NDCG\n",
    "ndcg_rs2 = ndcg_score([true_ratings_rs2], [estimated_ratings])\n",
    "print(f\"NDCG for RS2 (Neural Collaborative Filtering): {ndcg_rs2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f892650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID is?:15\n",
      "52/52 [==============================] - 0s 1ms/step\n",
      "\n",
      "Top 10 Recommended Movies with Novelty Scores for User 15:\n",
      "1182. MovieID: 1182.0, Predicted Rating: 4.904898643493652, Novelty Score: 0.1111111111111111\n",
      "119. MovieID: 119.0, Predicted Rating: 4.728442192077637, Novelty Score: 0.003952569169960474\n",
      "763. MovieID: 763.0, Predicted Rating: 4.693665504455566, Novelty Score: 0.011235955056179775\n",
      "486. MovieID: 486.0, Predicted Rating: 4.616649150848389, Novelty Score: 0.005154639175257732\n",
      "604. MovieID: 604.0, Predicted Rating: 4.613925933837891, Novelty Score: 0.006134969325153374\n",
      "1072. MovieID: 1072.0, Predicted Rating: 4.606298923492432, Novelty Score: 0.16666666666666666\n",
      "991. MovieID: 991.0, Predicted Rating: 4.6060991287231445, Novelty Score: 0.017543859649122806\n",
      "357. MovieID: 357.0, Predicted Rating: 4.605318069458008, Novelty Score: 0.002136752136752137\n",
      "63. MovieID: 63.0, Predicted Rating: 4.58200216293335, Novelty Score: 0.010752688172043012\n",
      "1176. MovieID: 1176.0, Predicted Rating: 4.581923961639404, Novelty Score: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "# Function to calculate novelty based on item popularity\n",
    "def calculate_novelty(trainset):\n",
    "    try:\n",
    "        # Count the number of ratings for each item\n",
    "        item_ratings_count = defaultdict(int)\n",
    "        for uid, iid, _ in trainset.all_ratings():\n",
    "            item_ratings_count[iid] += 1\n",
    "\n",
    "        # Calculate novelty scores for each item\n",
    "        novelty_scores = {iid: 1 / (1 + item_ratings_count[iid]) for iid in range(1, trainset.n_items + 1)}\n",
    "\n",
    "        return novelty_scores\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_novelty: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Function to get movie recommendations for a user using the deep learning model (RS2) with novelty scores\n",
    "def get_movie_recommendations_with_novelty(user_id, model, trainset, num_recommendations=10):\n",
    "    try:\n",
    "        # Get all item IDs\n",
    "        all_item_ids = np.array(list(range(1, trainset.n_items + 1)))\n",
    "\n",
    "        # Repeat the user ID for all items\n",
    "        user_ids = np.full_like(all_item_ids, user_id)\n",
    "\n",
    "        # Predict ratings for the user and all items\n",
    "        ratings = model.predict([user_ids, all_item_ids])\n",
    "\n",
    "        # Create DataFrame with item IDs and predicted ratings\n",
    "        predictions_df = pd.DataFrame({'item': all_item_ids, 'predicted_rating': ratings.flatten()})\n",
    "\n",
    "        # Exclude items the user has already rated\n",
    "        user_ratings = trainset.ur[user_id]\n",
    "        rated_item_ids = [iid for (iid, _) in user_ratings]\n",
    "        predictions_df = predictions_df[~predictions_df['item'].isin(rated_item_ids)]\n",
    "\n",
    "        # Sort items by predicted rating in descending order\n",
    "        top_recommendations = predictions_df.sort_values(by='predicted_rating', ascending=False).head(num_recommendations)\n",
    "\n",
    "        # Calculate novelty scores for the recommended items\n",
    "        novelty_scores = calculate_novelty(trainset)\n",
    "\n",
    "        # Add novelty scores to the recommendations\n",
    "        top_recommendations['novelty_score'] = top_recommendations['item'].map(novelty_scores)\n",
    "\n",
    "        return top_recommendations\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_movie_recommendations_with_novelty: {e}\")\n",
    "        traceback.print_exc()  # Print the traceback for more details\n",
    "        return None\n",
    "\n",
    "user_id_to_recommend = int(input(\"userID is?:\"))\n",
    "recommendations_with_novelty = get_movie_recommendations_with_novelty(user_id_to_recommend, model_rs2, trainset)\n",
    "\n",
    "# Display the top N recommended movies with novelty scores\n",
    "print(f'\\nTop {num_recs} Recommended Movies with Novelty Scores for User {user_id_to_recommend}:')\n",
    "for i, row in recommendations_with_novelty.iterrows():\n",
    "    print(f\"{i + 1}. MovieID: {row['item']}, Predicted Rating: {row['predicted_rating']}, Novelty Score: {row['novelty_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc496b",
   "metadata": {},
   "source": [
    "Code to find Movie through MovieID using movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac52705c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter MovieID: 3\n",
      "Movie Title for MovieID 3: Grumpier Old Men (1995)\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "\n",
    "# Define a function to get movie details based on MovieID\n",
    "def get_movie_details(movie_id):\n",
    "    if movie_id in movies_df['movieId'].unique():\n",
    "        movie_title = movies_df.loc[movies_df['movieId'] == movie_id, 'title'].values[0]\n",
    "        return movie_title\n",
    "    else:\n",
    "        return f\"Movie with ID {movie_id} not found in the dataset.\"\n",
    "\n",
    "movie_id_to_check = int(input(\"Enter MovieID: \"))\n",
    "\n",
    "# Check if MovieID is within the range of MovieIDs in the dataset\n",
    "if movie_id_to_check <= movies_df['movieId'].max():\n",
    "    movie_title = get_movie_details(movie_id_to_check)\n",
    "    print(f\"Movie Title for MovieID {movie_id_to_check}: {movie_title}\")\n",
    "else:\n",
    "    print(f\"MovieID {movie_id_to_check} is out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92d6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
